# Memory System for RAG Pipeline

H·ªá th·ªëng memory cho RAG pipeline h·ªó tr·ª£ h·ªôi tho·∫°i ƒëa l∆∞·ª£t (multi-turn conversation) v·ªõi kh·∫£ nƒÉng ghi nh·ªõ ng·ªØ c·∫£nh ng·∫Øn h·∫°n v√† d√†i h·∫°n.

## üèóÔ∏è Ki·∫øn tr√∫c

```
Memory System
‚îú‚îÄ‚îÄ ShortTermMemory      # L∆∞u tr·ªØ h·ªôi tho·∫°i g·∫ßn ƒë√¢y trong session
‚îú‚îÄ‚îÄ LongTermMemory       # L∆∞u tr·ªØ l·ªãch s·ª≠ d√†i h·∫°n v·ªõi vector search
‚îî‚îÄ‚îÄ ConversationManager  # Qu·∫£n l√Ω v√† merge context t·ª´ c·∫£ hai
```

## üì¶ Components

### 1. ShortTermMemory

**Ch·ª©c nƒÉng**: L∆∞u tr·ªØ c√°c message g·∫ßn ƒë√¢y trong session hi·ªán t·∫°i (in-memory).

**T√≠nh nƒÉng**:
- Window-based retrieval (N message g·∫ßn nh·∫•t)
- TTL t·ª± ƒë·ªông cleanup
- Thread-safe operations
- Session management

**S·ª≠ d·ª•ng**:
```python
from memory import ShortTermMemory

short_term = ShortTermMemory(max_messages_per_session=20, ttl_hours=24)

# L∆∞u message
short_term.store_message("session_123", "Hello", "user")

# L·∫•y l·ªãch s·ª≠ g·∫ßn ƒë√¢y
history = short_term.get_recent_history("session_123", window_size=5)
```

### 2. LongTermMemory

**Ch·ª©c nƒÉng**: L∆∞u tr·ªØ l·ªãch s·ª≠ h·ªôi tho·∫°i d√†i h·∫°n v·ªõi vector search trong Qdrant.

**T√≠nh nƒÉng**:
- Vector embedding v√† semantic search
- User profiling v√† context summarization
- Advanced filtering (user_id, session_id, timestamp)
- Data cleanup t·ª± ƒë·ªông

**S·ª≠ d·ª•ng**:
```python
from memory import LongTermMemory

long_term = LongTermMemory(collection_name="conversation_memory")

# L∆∞u message
long_term.store_message("session_123", "I have a headache", "user", user_id="user_1")

# Truy xu·∫•t message li√™n quan
related = long_term.retrieve_relevant_history("What about my medical history?", user_id="user_1")

# T√≥m t·∫Øt user profile
profile = long_term.get_user_context_summary("user_1")
```

### 3. ConversationManager

**Ch·ª©c nƒÉng**: Qu·∫£n l√Ω vi·ªác merge context t·ª´ short-term v√† long-term memory.

**T√≠nh nƒÉng**:
- Smart context merging
- Context truncation ƒë·ªÉ tr√°nh token overflow
- Priority-based context (current query > short-term > long-term)
- Error handling v·ªõi fallback mechanism

**S·ª≠ d·ª•ng**:
```python
from memory import ConversationManager

conv_manager = ConversationManager(
    max_context_tokens=2048,
    short_term_window=5,
    long_term_k=3
)

# L·∫•y enriched context
context = conv_manager.get_enriched_context(
    session_id="session_123",
    current_query="Should I see a doctor?",
    user_id="user_1"
)

# C·∫≠p nh·∫≠t memory
conv_manager.update_memory("session_123", "Hello", "user", user_id="user_1")
```

## üöÄ T√≠ch h·ª£p v·ªõi RAG Pipeline

### S·ª≠ d·ª•ng ConversationalLLM_RAG

```python
from inference_pipeline import ConversationalLLM_RAG

# Kh·ªüi t·∫°o
conv_rag = ConversationalLLM_RAG(
    max_context_tokens=2048,
    short_term_window=5,
    long_term_k=3
)

# Chat v·ªõi conversation context
result = conv_rag.generate(
    query="What about my medical history?",
    session_id="session_123",
    user_id="user_1",
    enable_conversation=True
)

print(result["answer"])
print(result["conversation_history"])  # Context ƒë∆∞·ª£c s·ª≠ d·ª•ng
```

### Fallback Mechanism

H·ªá th·ªëng t·ª± ƒë·ªông fallback v·ªÅ RAG pipeline g·ªëc n·∫øu:
- Memory components kh√¥ng kh·∫£ d·ª•ng
- C√≥ l·ªói trong conversation processing
- User t·∫Øt conversation mode

## üîß Configuration

### Environment Variables

Th√™m v√†o `.env`:
```bash
# Memory settings
CONVERSATION_MEMORY_COLLECTION="conversation_memory"
MAX_CONTEXT_TOKENS=2048
SHORT_TERM_WINDOW=5
LONG_TERM_K=3
```

### Settings.py

```python
# Memory config
CONVERSATION_MEMORY_COLLECTION: str = "conversation_memory"
MAX_CONTEXT_TOKENS: int = 2048
SHORT_TERM_WINDOW: int = 5
LONG_TERM_K: int = 3
```

## üß™ Testing

Ch·∫°y test ƒë·ªÉ verify t√≠ch h·ª£p:

```bash
python test_conversation_integration.py
```

## üìä Monitoring

### Memory Stats

```python
# L·∫•y th·ªëng k√™ memory system
stats = conv_rag.get_memory_stats()
print(stats)
```

### User Profiling

```python
# L·∫•y profile user
profile = conv_rag.get_user_profile("user_1")
print(profile)
```

### Session Management

```python
# Th√¥ng tin session
session_info = conv_rag.get_session_info("session_123")

# X√≥a session
conv_rag.clear_session("session_123")
```

## üö® Error Handling

### Graceful Degradation

- N·∫øu Qdrant kh√¥ng kh·∫£ d·ª•ng ‚Üí ch·ªâ s·ª≠ d·ª•ng short-term memory
- N·∫øu embedding model l·ªói ‚Üí fallback v·ªÅ standard RAG
- N·∫øu memory operations fail ‚Üí continue v·ªõi query g·ªëc

### Logging

```python
import logging
logging.basicConfig(level=logging.INFO)

# Memory operations s·∫Ω log chi ti·∫øt
```

## üîÆ Future Enhancements

- [ ] Redis backend cho short-term memory
- [ ] Conversation summarization v·ªõi LLM
- [ ] Advanced topic tracking
- [ ] Multi-user conversation support
- [ ] Conversation analytics v√† insights

## üìù Example Use Cases

### 1. Medical Consultation

```python
# L∆∞·ª£t 1
result1 = conv_rag.generate("I have a headache", session_id="medical_123", user_id="patient_1")

# L∆∞·ª£t 2 - s·ª≠ d·ª•ng context t·ª´ l∆∞·ª£t 1
result2 = conv_rag.generate("What about my medical history?", session_id="medical_123", user_id="patient_1")
```

### 2. Customer Support

```python
# L∆∞·ª£t 1
result1 = conv_rag.generate("My order hasn't arrived", session_id="support_456", user_id="customer_1")

# L∆∞·ª£t 2 - bot nh·ªõ v·ªÅ order issue
result2 = conv_rag.generate("Can you check the status?", session_id="support_456", user_id="customer_1")
```

### 3. Educational Assistant

```python
# L∆∞·ª£t 1
result1 = conv_rag.generate("Explain machine learning", session_id="edu_789", user_id="student_1")

# L∆∞·ª£t 2 - ti·∫øp t·ª•c topic ML
result2 = conv_rag.generate("What about deep learning?", session_id="edu_789", user_id="student_1")
``` 